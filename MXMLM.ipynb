{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML, TEI, CMI/F and data handling\n",
    "from bs4 import BeautifulSoup # Hent BeautifulSoup-modulen (https://www.crummy.com/software/BeautifulSoup/) for XML\n",
    "from bs4 import Comment # BS4-addon for å håndtere kommentarer <!-- X -->\n",
    "import re # Regex\n",
    "import pandas as pd\n",
    "import collections # Facilitate dynamic dict\n",
    "\n",
    "# Time and date\n",
    "import datetime # Dates\n",
    "from datetime import date\n",
    "import time # Time\n",
    "\n",
    "# File and folder handling\n",
    "import glob # The yeast of thought and mind\n",
    "import os # Filsystem; mapper, lagring, åpning, etc...\n",
    "import shutil # Se os+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *MunchXMLmuncher*\n",
    "Developed by research assistant Loke Sjølie for the University of Oslo\n",
    "\n",
    "This script currently consumes 1 file in eMunch's TEIXML format and converts it to a complete CMIF/TEIXML file. The script is customized to ensure high precision, with fallbacks designed around their particular TEIXML files. Be aware that CMIF is purely intended to represent correspondance between individuals, and as such there is *significant* (intentional) data loss in converting to the format.\n",
    "\n",
    "The script targets documents that have been tagged with **\"brev\"** or **\"letter\"**, and extracts from these:\n",
    "1. Document ID, which is extrapolated to form an eMunch URL\n",
    "2. Document Author tends to be Edvard Munch, and he is given his customary VIAF ID\n",
    "3. Document Authored Date, which is converted to YYYY-MM-DD (or YYYY-MM, or YYYY) or a range that can be from or from-to\n",
    "4. Document Recipient(s), names and IDs\n",
    "\n",
    "... and then places these in a hierarchy: <CorrespDesc(DocumentID)><*Author*><*Date*/><*/Author*><*Recipient*(s)/>.\n",
    "\n",
    "The file I was provided does **not** specify locations, but I'm sure that we'll be able to work out how to add those if such information is available. Further development: use glob.glob<sup>(the yeast of thought and mind)</sup> to consume files by folder. Add location data? Redirect recipient IDs to VIAF?\n",
    "\n",
    "The script can be altered to target all documents with one or more recipients, but many of the documents within that criteria are drafts and/or notes. Alternatively, the script can be further restricted to target only letters with \"brev\"/\"letter\" type *and* one or more recipients - but the test file has 0 instances where this would have an effect.\n",
    "___\n",
    "Users:\n",
    "I ask that you do not touch anything below the header **Program** unless you *sort of* know what you're doing. :)\n",
    "\n",
    "## CMIF Metadata & options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"0.9\" # Describes the \"program's\" state of completion and versioning.\n",
    "cmifUid = \"a403c593-09df-4538-8acf-8d459339fca8\" # Unique ID. Used in sourceDesc of CMIF. Don't change it without a good reason.\n",
    "# cmifUid is also used as \"source\" for the time being in each object. Read more about this in CMIF docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init, metadata, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today() # Sett dato i dag\n",
    "today = today.strftime(\"%Y-%m-%d\") # Formater dato\n",
    "currVer = version+\" \"+today\n",
    "\n",
    "previouslyRun = \"Last executed code was version \"+str(currVer)+\". All OUTPUT files are current to that version on that date.\\n\"+str(cmifUid)+\".\"\n",
    "print(\"Version\",currVer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users: only edit things that exist WITHIN double quotation marks (\"\").\n",
    "cmifTitle = \"MunchXMLmuncher version \"+str(version) # Title of resulting CMIF\n",
    "editorName = \"Loke Sjølie\" # The name to issue to the CMIF file as \"editor\" (responsible for this file)\n",
    "editorMail = \"loke.sjolie@ub.uio.no\" # The e-mail associated with the above.\n",
    "\n",
    "#publishers = 1 # How many publishers? Add later if required.\n",
    "publisherURL = \"eMunch.no\" # Website of publisher #1\n",
    "publisherName = \"eMunch\" # Name of publisher #1\n",
    "\n",
    "cmifURL = \"eMunch.no\" # URL where this file is located\n",
    "typeOfBibl = \"online\" # The type of bibliography that is being described\n",
    "publicationStatementFull = \"[Full bibliographical statement of the scholarly edition or repository where this file points to]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasCorrespondenceXML,hasTEIXML,hasChrono,hasXMLs = False,False,False,False\n",
    "programfolder = \"MXMLM \"+currVer\n",
    "if os.path.exists(programfolder):\n",
    "    print(\"Found directory '% s'\" % programfolder)\n",
    "else:\n",
    "    os.mkdir(programfolder)\n",
    "    print(\"Directory '% s' created\" % programfolder)\n",
    "inputfolder = os.path.join(programfolder,\"sourcefiles\") # The folder containing the TEI/XML-files to be transformed.\n",
    "paths = ['correspondence.xml','register_tei.xml']\n",
    "if not os.path.exists(inputfolder):\n",
    "    os.mkdir(inputfolder)\n",
    "    print(\"Directory '% s' created\" % inputfolder)\n",
    "outputfolder = os.path.join(programfolder,\"output\") # Output folder\n",
    "if not os.path.exists(outputfolder):\n",
    "    os.mkdir(outputfolder)\n",
    "    print(\"Directory '% s' created\" % outputfolder)\n",
    "    \n",
    "lookupChrono = sorted(glob.glob(\"*Kronologi_Munchs_brev*.xlsx\"), key=os.path.getmtime)\n",
    "x = len(lookupChrono)-1\n",
    "if x > -1:\n",
    "    print(\"Newest chronology file:\",lookupChrono[x])\n",
    "    chronologyFile = lookupChrono[x]\n",
    "    hasChrono = True\n",
    "    shutil.copy2(chronologyFile, inputfolder+\"/kronologi.xlsx\")\n",
    "    chronologyFile = inputfolder+\"/kronologi.xlsx\"\n",
    "else:\n",
    "    print(\"No chronology file provided. Skipping datetime augmentation.\")\n",
    "if os.path.isfile(\"ID_sted-verdier.xlsx\"):\n",
    "    print(\"Detected ID_sted-verdier.xlsx\")\n",
    "    if os.path.exists(\"xml-filer\"):\n",
    "        print(\"XML>CMIF placename augmentation enabled\")\n",
    "        listXMLfiles = glob.glob(\"xml-filer/**/*.xml\",recursive=True)\n",
    "        hasXMLs = True\n",
    "        f = open(programfolder+\"/xml_directory.txt\", \"w\")\n",
    "        f.write(str(listXMLfiles))\n",
    "        f.close()\n",
    "    else:\n",
    "        print(\"No XML files provided. XML>CMIF placename augmentation disabled\")\n",
    "else:\n",
    "    print(\"No ID_sted-verdier file provided. Skipping placename augmentation.\")\n",
    "\n",
    "    \n",
    "for item in paths:\n",
    "    if os.path.isfile(item):\n",
    "        a = os.path.getmtime(item)\n",
    "        if os.path.isfile(inputfolder+\"/\"+item):\n",
    "            b = os.path.getmtime(inputfolder+\"/\"+item)\n",
    "            print(\"Found existing instance of\",inputfolder+\"/\"+item)\n",
    "            if a>b:\n",
    "                shutil.copy2(item, inputfolder+\"/\"+item)\n",
    "                print(\"\\tReplaced older version of\",item,\"in\",inputfolder,\"(file's last modified date difference is +\"+str(a-b)+str(\")\"))\n",
    "            else:\n",
    "                print(\"\\tUsing existing version of\",item,\"(file's last modified date difference is\",str(a-b)+str(\")\"))\n",
    "            if item == \"correspondence.xml\":\n",
    "                hasCorrespondenceXML = True\n",
    "            elif item == \"register_tei.xml\":\n",
    "                hasTEIXML = True\n",
    "        else:\n",
    "            shutil.copy2(item, inputfolder+\"/\"+item)\n",
    "            print(\"\\tYoink! Copied\",item,\"to\",inputfolder)\n",
    "            if item == \"correspondence.xml\":\n",
    "                hasCorrespondenceXML = True\n",
    "            elif item == \"register_tei.xml\":\n",
    "                hasTEIXML = True\n",
    "    else:\n",
    "        if os.path.isfile(inputfolder+\"/\"+item):\n",
    "            print(\"\\tFound existing file\",item,\"in the sourcefiles directory, but not in the main directory.\")\n",
    "            if item == \"correspondence.xml\":\n",
    "                hasCorrespondenceXML = True\n",
    "            elif item == \"register_tei.xml\":\n",
    "                hasTEIXML = True\n",
    "        else:\n",
    "            print(\"\\nWARNING Didn't find\",item,\"in any of the working directories!\\n\")\n",
    "filesForMunching = glob.glob(inputfolder+\"/*\")\n",
    "if len(filesForMunching) == 0:\n",
    "    print(\"Stop! You need to put some file/s (correspondence.xml,register_tei.xml) in the sourcefiles folder for me to eat!\")\n",
    "    raise KeyboardInterrupt\n",
    "elif hasTEIXML == False and hasCorrespondenceXML == False:\n",
    "    print(\"Critical error! I didn't find either of the correspondence.xml OR register_tei.xml files. Means I don't have anything to munch!\")\n",
    "    raise KeyboardInterrupt\n",
    "else:\n",
    "    print(\"\\nSummary:\")\n",
    "    for name in filesForMunching:\n",
    "        if name == inputfolder+\"\\\\correspondence.xml\" or name == inputfolder+\"\\\\register_tei.xml\":\n",
    "            print('\\t'+name,'will be used')\n",
    "        elif name == inputfolder+\"\\\\kronologi.xlsx\":\n",
    "            print('\\tChronology file will be used')\n",
    "        else:\n",
    "            print(\"\\tWARNING Detected unusual file!\",name,\"may not be a file I can munch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for XML letter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasXMLs == True: # If the XML files should be used for updating\n",
    "    placenamedict = collections.defaultdict(dict)\n",
    "    #placenamedict = {}\n",
    "    addrsFoundInXMLs = [] # Make a simple list to hold the short names of every file we've found addresses for\n",
    "    xmlswithnoaddress = []\n",
    "    plainnames = []\n",
    "    i=0\n",
    "    countAddrsD = 0\n",
    "    countAddrsA = 0\n",
    "    for item in listXMLfiles:\n",
    "        find_address = []\n",
    "        findFileName = item.split(\"\\\\\") # Make filepath a list\n",
    "        findFileName = findFileName[len(findFileName)-1] # Get the path destination file\n",
    "        chkStr = findFileName[0:2]\n",
    "        if chkStr == \"PN\":\n",
    "            filenamePlain = findFileName[0:6] # Must be regulated to remove .xml as well as pagination from filename\n",
    "            #print(findFileName,filenamePlain)\n",
    "        elif chkStr == \"No\":\n",
    "            filenamePlain = findFileName[0:11] # Must be regulated to remove .xml as well as pagination from filename\n",
    "            #print(findFileName,filenamePlain)\n",
    "        else:\n",
    "            print(\"PROBLEM\")\n",
    "        if filenamePlain not in plainnames:\n",
    "            plainnames.append(str(filenamePlain))\n",
    "        print (\"\\r\",\"Progress:\",round(i/len(listXMLfiles)*100),\"%\", end='')\n",
    "        \n",
    "        if filenamePlain in addrsFoundInXMLs: # if we found the address for this xml\n",
    "            pass # Skip if we've already found an address for this XML filename\n",
    "        else:\n",
    "            with open(item, \"r\", encoding=\"utf-8\") as file: # Open a file\n",
    "                letterfile = file.readlines() # Les innholdet som linjer\n",
    "                letterfile = \"\".join(letterfile) # Linjene blir kombinert i en variabel\n",
    "            soup = BeautifulSoup(letterfile) # It is now soup\n",
    "            find_address = soup.findAll(\"address\") # Look for addrline element.\n",
    "            #augh,addrKey = \"\",\"\" # Reset\n",
    "            foundSender,foundRecipient = False,False # Reset\n",
    "\n",
    "            ## Code below enables seeking address lines in the letters.\n",
    "            ## It is intentionally disabled at this time because there is no decisive way to get only\n",
    "            ## the actual addresses of the sender(s) and the recipient(s).\n",
    "            #if find_address: # If there's an addrline element:\n",
    "            #    print(\"Address in\",findFileName)\n",
    "            #    recipNo = 0\n",
    "            #    senderNo = 0\n",
    "            #    addrcount = -1\n",
    "            #    for addr in find_address:\n",
    "            #        augh,addrKey,isSender = \"\",\"\",\"\" # Reset\n",
    "            #        addrcount +=1\n",
    "            #        if len(find_address) > 1:\n",
    "            #            print(\"\\n\\n\",findFileName,\"\\n\\n\")\n",
    "            #        isSender = find_address[addrcount].get(\"n\")\n",
    "            #        if isSender == \"discussed\":\n",
    "            #            pass # Ignore discussed persons/addresses. Reason: irrelevant.\n",
    "            #        elif not isSender:\n",
    "            #            pass\n",
    "            #            #print(\"IGNORED: Address not tagged as sender or recipient\",findFileName)\n",
    "            #        else:\n",
    "            #            print(isSender,find_address[addrcount])\n",
    "            #            try:\n",
    "            #                augh = find_address[addrcount].findChild(\"placename\", recursive=True) # Get the placename in the addrline\n",
    "            #                try:\n",
    "            #                    addrKey = augh.get('key')\n",
    "            #                    if addrKey:\n",
    "            #                        countAddrsA+=1\n",
    "            #                        if isSender == \"sender\":\n",
    "            #                            senderNo+=1\n",
    "            #                            #print(\"\\tSENDER\",addrKey)\n",
    "            #                            placenamedict[filenamePlain][\"sender\"+str(senderNo)] = addrKey\n",
    "            #                            foundSender = True\n",
    "            #                        elif isSender == \"recipient\":\n",
    "            #                            recipNo+=1\n",
    "            #                            placenamedict[filenamePlain][\"recipient\"+str(recipNo)] = addrKey\n",
    "            #                            foundRecipient = True\n",
    "            #                            #print(\"\\tRECIPIENT\",addrKey)\n",
    "            #                        else:\n",
    "            #                            print(\"\\nWTF?\\n\",addrKey)\n",
    "            #                            countAddrsA-=1\n",
    "            #                        addrsFoundInXMLs.append(filenamePlain) # Add the filename to the list of XMLs already found\n",
    "            #                    else:\n",
    "            #                        print(\"Accessed key, but it was counted as false?\",addrKey)\n",
    "            #                except:\n",
    "            #                    print(\"No key in placename\",augh)\n",
    "            #            except:\n",
    "            #                print(\"No placename child element\")\n",
    "\n",
    "            ## Code below enables retrieval of an address enclosed in a dateline element.\n",
    "            ## This is understood to be the sender's address.\n",
    "            if foundSender == False: # If a recipient has not been found\n",
    "                find_address = soup.find(\"dateline\") # Look for a dateline element\n",
    "                if find_address: # If there is a dateline element:\n",
    "                    #print(\"Dateline in\",findFileName)\n",
    "                    find_address = find_address.findChild(\"placename\", recursive=True) # Get the placename\n",
    "                    #print(\"DATELINE\",find_address)\n",
    "                    try: # There are documents with datelines but no dates in them confirmed.\n",
    "                        addrKey = find_address.get('key') # Get the internal ID of the placename\n",
    "                        addrKey = addrKey.replace(\"pl\",\"\") # Remove \"pl\" prefix\n",
    "                        addrsFoundInXMLs.append(filenamePlain) # Add the filename to the list of XMLs already found\n",
    "                        placenamedict[filenamePlain][\"sender\"] = addrKey\n",
    "                        foundSender = True\n",
    "                        #print(\"\\tSENDER\",filenamePlain,addrKey)\n",
    "                        #prefix = \"DATELINE\" # debug\n",
    "                        countAddrsD+=1 # Count it\n",
    "\n",
    "                    except:\n",
    "                        if filenamePlain not in xmlswithnoaddress:\n",
    "                            xmlswithnoaddress.append(filenamePlain)\n",
    "                        #print(\"Dateline without address in\",findFileName)\n",
    "                else:\n",
    "                    if filenamePlain not in xmlswithnoaddress:\n",
    "                        xmlswithnoaddress.append(filenamePlain)\n",
    "            #if find_address: # If there's a value in find_address after checking for addrline/dateline\n",
    "            #    addrKey = find_address.get('key') # Get the internal ID of the placename\n",
    "            #    #print(prefix,filenamePlain,addrKey,\"\\n\") # debug\n",
    "            #    addrsFoundInXMLs.append(filenamePlain) # Add the filename to the list of XMLs already found\n",
    "            #    # we skip in order to DRASTICALLY increase the speed at which we process the XMLs at minimal cost.\n",
    "        i+=1\n",
    "print(\"\")\n",
    "for xmlname in addrsFoundInXMLs:\n",
    "    if xmlname in xmlswithnoaddress:\n",
    "        xmlswithnoaddress.remove(xmlname)\n",
    "print(\"# Plain names:\",len(plainnames),\"\\n# With placenames:\",len(placenamedict),\"# Without:\",len(xmlswithnoaddress),\"\\t\",len(xmlswithnoaddress)+len(placenamedict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read chronology\n",
    "The chronology's document ID formatting does not match the formatting found everywhere else. This step includes a large portion of data massaging that catches erroneous names (\"M N 2714\",\"N 3491\"), applies formatting to match the patterns, and checks for duplicates in data.\n",
    "\n",
    "After correcting bad formatting in names, the script attempts to fetch the dates associated with each where available. The script attempts to correct for the following data formats: DD.MM.YYYY, ??.MM.YYYY, ?D.M?.YYYY, MM.-MM.YYYY, MM-MM.YYYY, YYYY-YYYY and... several more. I have gotten to a point where only the most malformed of dates are allowed to pass by - these include instances of 23.07.1895/1896, 2[6/7].12.1912, and other equally-mangled date formats. After retrieving the date (if capable of doing so), the script reformats all dates to match YYYY-MM-DD format, dropping pairs where incomplete in the order of DD>MM>YYYY to ensure that the resulting data set is as confident as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step requires several customised workarounds to handle the irregular and non-machine-readable data present in\n",
    "# the date file. As a result, it can accept a broad range of dates.\n",
    "if hasChrono == True:\n",
    "    j = []\n",
    "    datesNotAdded = []\n",
    "    dupes = []\n",
    "    chronology = pd.read_excel(chronologyFile).dropna(axis=1, how='all').dropna(axis=0, how='all').reset_index(drop=True)\n",
    "    chronology = chronology.fillna(\"N/A\")\n",
    "    try:\n",
    "        if placenamedict:\n",
    "            print(\"Placenamedict found with content\")\n",
    "        else:\n",
    "            print(\"Placenamedict found without content\")\n",
    "    except:\n",
    "        placenamedict = collections.defaultdict(dict)\n",
    "        print(\"Made new dict\")\n",
    "    i=0\n",
    "    for idx,row in chronology.iterrows():\n",
    "        document = chronology.iloc[idx]['Objektnr.']\n",
    "        skipThis = False\n",
    "        if document != \"N/A\":\n",
    "            chkStr = document[0:2]\n",
    "            if chkStr == \"PN\":\n",
    "                #print(document)\n",
    "                document = document.replace(\" \",\"0\")\n",
    "                if len(document) == 5:\n",
    "                    filenameEdited=document[:2] + \"0\" + document[len(document)-3:]\n",
    "                else:\n",
    "                    filenameEdited = document[:2] +\"000\"+ document[len(document)-4:]\n",
    "                    filenameEdited = filenameEdited[:2] + filenameEdited[len(filenameEdited)-4:]\n",
    "                filenamePlain = filenameEdited[0:6]\n",
    "            elif chkStr == \"MM\":\n",
    "                #No-MM_K0499\n",
    "                #filenamePlain = document[0:11]\n",
    "                if len(document) == 8:\n",
    "                    #print(document)\n",
    "                    filenamePlain = document[:2]+\"_\"+document[3]+\"0\"+document[5:]\n",
    "                else:\n",
    "                    filenamePlain = document[:2]+\"_\"+document[3]+document[5:]\n",
    "                filenamePlain = \"No-\"+filenamePlain\n",
    "            elif chkStr == \"M \": # Implemented to catch \"M N 2714\"...\n",
    "                filenamePlain = document[:1]+\"_\"+document[2]+document[4:]\n",
    "                filenamePlain = \"No-M\"+filenamePlain\n",
    "                #filenamePlain = filenamePlain.replace(\" \",\"\")\n",
    "                print(\"Caught\",document,\">\",filenamePlain)\n",
    "            elif chkStr == \"N \": # Implemented to catch \"N 3491\"...\n",
    "                  # This is ASSUMED to be \"No-MM_N3491\" and not PN3491\n",
    "                filenamePlain = \"No-MM-N_\"+document[2:]\n",
    "                print(\"Caught\",document,\">\",filenamePlain)\n",
    "            elif chkStr == \" M\": # Implemented to catch \" MM N 723\"...\n",
    "                filenamePlain = document[1:3]+\"_\"+document[4]+\"0\"+document[6:]\n",
    "                print(\"Caught\",document,\">\",filenamePlain)\n",
    "            else:\n",
    "                print(\"!!\\tError in\",document,\"length:\",len(document))\n",
    "                filenamePlain = \"Formatting error\"\n",
    "            #print(filenamePlain)\n",
    "            \n",
    "            if filenamePlain != \"Formatting error\":\n",
    "                #date = chronology.iloc[i]['Dato']\n",
    "                if filenamePlain in j:\n",
    "                    dupes.append(filenamePlain)\n",
    "                    #print(\"Found duplicate\",filenamePlain)\n",
    "                else:\n",
    "                    j.append(filenamePlain)\n",
    "                ### This indent for dates after fixing the naming conventions\n",
    "                fromMonth,fromYear,toMonth,toYear,dateobject,Year,fromDate,toDate = False,False,False,False,False,False,False,False\n",
    "                #newYear,newMonth,newDay = \"\",\"\",\"\"\n",
    "                dateobject = chronology.iloc[idx]['Dato']\n",
    "\n",
    "                if dateobject != \"N/A\": # If date object isn't N/A\n",
    "                    if isinstance(dateobject,datetime.date): # If it's just a datetime object\n",
    "                        dateobject = dateobject.strftime(\"%Y-%m-%d\") # We're done! Yay!\n",
    "                        #print(idx,\"datetime DATE:\",dateobject)\n",
    "                    else: # If it's not a datetime object:\n",
    "                        dateobject = str(dateobject)\n",
    "                        #if \"..\" in dateobject: \n",
    "                        dateobject = dateobject.replace(\"..\",\".\") # Sometimes there's double dots (..)...\n",
    "                        dateobject = dateobject.replace(\"??.\",\"\") # Remove trash dates\n",
    "                        if \"?\" in dateobject[0:2]:\n",
    "                            dateobject = dateobject[3:]\n",
    "                        if \"?\" in dateobject[0:2]:\n",
    "                            dateobject = dateobject[3:]\n",
    "                        #chkDt = dateobject[0:2] # First 2 letters\n",
    "                        #dateobject = dateobject.replace(\"/\",\"-\")\n",
    "                        #dateobjectlist = dateobject.split(\".\")\n",
    "                        dateobject = dateobject.replace(\"–\",\"-\") # Yes, there are a few dates separated by long dash...\n",
    "                        if \"-\" in dateobject: # Used for cases where there may be - or / used as separator.\n",
    "                            sep = \"-\"\n",
    "                        else:\n",
    "                            sep = \"/\"\n",
    "                        if re.match(\"^([0]?[1-9]|[1|2][0-9]|[3][0|1])[./-]([0]?[1-9]|[1][0-2])[./-]([0-9]{4}|[0-9]{2})$\",dateobject):\n",
    "                            # Full date\n",
    "                            dateobjectsplit = dateobject.split(\".\")\n",
    "                            dateobject = dateobjectsplit[2]+\"-\"+dateobjectsplit[1]+\"-\"+dateobjectsplit[0]\n",
    "                            if len(dateobjectsplit[2]) != 4: # Only allow 4-digit years.\n",
    "                                #print(idx,\"COMPLETE DATE:\",dateobject)\n",
    "                                skipThis = True\n",
    "                           # else: # If it does not match\n",
    "                              #  skipThis = True\n",
    "                        elif re.match(\"^([0]?[1-9]|[1][0-2])[./-]([0-9]{4}|[0-9]{2})$\",dateobject): # Month.Year\n",
    "                            dateobjectsplit = dateobject.split(\".\")\n",
    "                            dateobject = dateobjectsplit[1]+\"-\"+dateobjectsplit[0]\n",
    "                            dateobject = dateobject#+\"-01\"\n",
    "                            if len(dateobjectsplit[1]) != 4: # Only allow 4-digit years.\n",
    "                                #print(idx,\"MONTH-YEAR DATE:\",dateobject)\n",
    "                                skipThis = True\n",
    "                            #else: # If it does not match\n",
    "                                #skipThis = True \n",
    "                        elif re.match(\"^([0]?[1-9]|[1][0-2])[./-]([0-9]{4}|[0-9]{2})[./-]([0]?[1-9]|[1][0-2])[./-]([0-9]{4}|[0-9]{2})$\",dateobject): # Month.Year\n",
    "                            # MM.YYYY/MM.YYYY\n",
    "                            # MM.YYYY-MM.YYYY\n",
    "                            dateobjectsplit = dateobject.split(sep)\n",
    "                            dateobjectsplitFrom = dateobjectsplit[0].split(\".\")\n",
    "                            dateobjectsplitTo = dateobjectsplit[1].split(\".\")\n",
    "                            fromMonth = dateobjectsplitFrom[0]\n",
    "                            fromYear = dateobjectsplitFrom[1]\n",
    "                            toMonth = dateobjectsplitTo[0]\n",
    "                            toYear = dateobjectsplitTo[1]\n",
    "                            fromDate = fromYear+\"-\"+fromMonth\n",
    "                            toDate = toYear+\"-\"+toMonth\n",
    "                            #dateobject = dateobjectsplit[1]+\"-\"+dateobjectsplit[0]\n",
    "                            #dateobject = dateobject+\"-01\"\n",
    "                            #if len(dateobjectsplit[1]) == 4: # Only allow 4-digit years.\n",
    "                            #print(idx,\"MONTH-YEAR/MONTH-YEAR DATE:\",fromDate,\"TO\",toDate)\n",
    "                            #else: # If it does not match\n",
    "                              #  pass # Discard \n",
    "                        elif re.match(\"^([0]?[1-9]|[1][0-2])[./-][/-]([0]?[1-9]|[1][0-2])[./-]([0-9]{4}|[0-9]{2})$\",dateobject):\n",
    "                            # Month.-Month.Year\n",
    "                            dateobjectsplit = dateobject.split(sep)\n",
    "                            dateobjectsplitA = dateobject[0:2]\n",
    "                            dateobjectsplitB = dateobjectsplit[1]\n",
    "                            dateobjectsplit = dateobjectsplitB.split(\".\")\n",
    "                            Year = dateobjectsplit[1]\n",
    "                            fromMonth = dateobjectsplitA\n",
    "                            toMonth = dateobjectsplit[0]\n",
    "                            fromDate = Year+\"-\"+fromMonth\n",
    "                            toDate = Year+\"-\"+toMonth\n",
    "\n",
    "                            #print(idx,\"Month.-month.year DATE:\",fromDate,\"TO\",toDate)\n",
    "\n",
    "                        elif re.match(\"^([0-9]{4}|[0-9]{2})$\",dateobject): # Year-only\n",
    "                            dateobject = dateobject#+\"-01-01\"\n",
    "                            if len(dateobject) != 4: # Only allow 4-digit years + 6 digits -01-01.\n",
    "                                #print(idx,\"YEAR ONLY DATE:\",dateobject)\n",
    "                                skipThis = True\n",
    "                            #else: # If it does not match\n",
    "                               # skipThis = True\n",
    "                        elif re.match(\"^([0-9]{4}|[0-9]{2})[./-]([0-9]{4}|[0-9]{2})$\",dateobject): # Year-year\n",
    "                            dateobject = dateobject.replace(\"/\",\"-\")\n",
    "                            daterange = dateobject.split(\"-\")\n",
    "                            fromyear = daterange[0]\n",
    "                            toyear = daterange[1]\n",
    "                            if len(fromyear) != 4 and len(toyear) != 4: # Only allow 4-digit years.\n",
    "                                skipThis = True\n",
    "                                #print(idx,\"YEAR-YEAR RANGE:\",fromyear,\"TO\",toyear)\n",
    "                            #else: # If it does not match\n",
    "                                \n",
    "                        else:\n",
    "                            print(idx,\"Dropped\",dateobject)\n",
    "                            datesNotAdded.append(dateobject)\n",
    "                            skipThis = True\n",
    "                        if skipThis == False:\n",
    "                            if fromDate != False and toDate != False:\n",
    "                                #print(filenamePlain,\"dated between\",fromDate,\"-\",toDate)\n",
    "                                placenamedict[filenamePlain][\"fromDate\"] = fromDate\n",
    "                                placenamedict[filenamePlain][\"toDate\"] = toDate\n",
    "                            else:\n",
    "                                #print(filenamePlain,\"dated\",dateobject)\n",
    "                                placenamedict[filenamePlain][\"date\"] = dateobject\n",
    "                        \n",
    "                \n",
    "                \n",
    "            #print(filenamePlain,\"|\",document)\n",
    "        i+=1\n",
    "#chronology\n",
    "print(\"\")\n",
    "for dupe in dupes:\n",
    "    print(\"Duplicate:\",dupe)\n",
    "print(\"Len of j:\",len(j),\"Len of placenamedict:\",len(placenamedict),\"\\nNo. dropped dates:\",len(datesNotAdded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for item in placenamedict:\n",
    "    sentFrom = placenamedict[item].get('sender')\n",
    "    if sentFrom:\n",
    "        i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get names of locations\n",
    "This step transforms the IDs acquired in the XML letter files into proper names. The script attempts to find the most precise name for the location available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasXMLs == True: # This step only affects placenames.\n",
    "    placenamedf = pd.read_excel(\"ID_sted-verdier.xlsx\").dropna(axis=1, how='all').dropna(axis=0, how='all').reset_index(drop=True)\n",
    "    placenamedf = placenamedf.fillna(\"N/A\")\n",
    "    for item in placenamedict:\n",
    "        print(item)\n",
    "        try:\n",
    "            print(\"\\tSent from:\",placenamedict[item]['sender'])\n",
    "            try:\n",
    "                placenameSearch = placenamedf[placenamedf['ID'].astype(str) == str(placenamedict[item]['sender'])]\n",
    "                stedsnavn = placenameSearch[\"sted\"].values[0]\n",
    "                regionnavn = placenameSearch[\"region, nasjonal\"].values[0]\n",
    "                landnavn = placenameSearch[\"land\"].values[0]\n",
    "                kontinent = placenameSearch[\"region, internasjonal\"].values[0]\n",
    "                if stedsnavn != \"N/A\":\n",
    "                    print(\"Sted:\",stedsnavn)\n",
    "                    placenamedict[item]['sender'] = stedsnavn\n",
    "                else:\n",
    "                    if regionnavn != \"N/A\":\n",
    "                        print(\"Region:\",regionnavn)\n",
    "                        placenamedict[item]['sender'] = regionnavn\n",
    "                    else:\n",
    "                        if landnavn != \"N/A\":\n",
    "                            print(\"Land:\",landnavn)\n",
    "                            placenamedict[item]['sender'] = landnavn\n",
    "                        else:\n",
    "                            if kontinent != \"N/A\":\n",
    "                                print(\"Kontinent:\",kontinent)\n",
    "                                placenamedict[item]['sender'] = kontinent\n",
    "                            else:\n",
    "                                print(\"Fant ikke stedsnavn.\")\n",
    "            except:\n",
    "                print(\"No match for\",str(placenamedict[item]['sender']))\n",
    "        except:\n",
    "            pass # Generally means that the entry has a date but not a location, and thus there is no need.\n",
    "        try: # Try finding the date value\n",
    "            date = placenamedict[item]['date']\n",
    "            print(\"\\tDated:\",date)\n",
    "        except: # No date value found\n",
    "            try: # Is there a fromdate and todate?\n",
    "                date = str(placenamedict[item]['fromDate'])+\" to \"+str(placenamedict[item]['toDate'])\n",
    "                print(\"\\tDated between:\",date)\n",
    "            except: # There is no date value and no fromdate and todate\n",
    "                pass # Skip it\n",
    "    #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read/process TEI-XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CMIF boilerplate object\n",
    "CMIFstring = '<?xml-model href=\"https://raw.githubusercontent.com/TEI-Correspondence-SIG/CMIF/master/schema/cmi-customization.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?><TEI xmlns=\"http://www.tei-c.org/ns/1.0\"><teiHeader><fileDesc><titleStmt><title>'+str(cmifTitle)+'</title><editor>'+str(editorName)+'<email>'+str(editorMail)+'</email></editor></titleStmt><publicationStmt><publisher><ref target=\"'+str(publisherURL)+'\">'+str(publisherName)+'</ref></publisher><idno type=\"url\">'+str(cmifURL)+'</idno> <date when=\"'+str(today)+'\"/><availability><licence target=\"https://creativecommons.org/licenses/by/4.0/\">This file is licensed under the terms of the Creative-Commons-License CC-BY 4.0</licence></availability></publicationStmt><sourceDesc><bibl type=\"'+str(typeOfBibl)+'\" xml:id=\"'+str(cmifUid)+'\">'+str(publicationStatementFull)+'</bibl></sourceDesc></fileDesc><profileDesc></profiledesc></teiheader></tei>'\n",
    "CMIF = BeautifulSoup(CMIFstring)\n",
    "start = time.time()\n",
    "\n",
    "# DEBUGGER LISTS\n",
    "documentsWithBadDates = []\n",
    "documentsWithNoAuthor = []\n",
    "documentsWithNoRecipient = []\n",
    "documentsLackingTargetReference = []\n",
    "\n",
    "# Declare variables\n",
    "# ---------------------------------------------------------------\n",
    "noOfLettersToMunch = 0\n",
    "changedDatesList,addedPlaceList = [],[]\n",
    "errors_found = [] # List of errors found during execution\n",
    "letterCount = 0 # # letters, as defined by an item having a recipient, processed\n",
    "miscCount = 0 # non-letter documents, as defined by an item having no recipients, processed\n",
    "addresseesUnique = [] # List of unique recipients\n",
    "datetype = 0 # Var for the type of date we're dealing with\n",
    "noOfRecipients = 0 # Counting non-unique recipients\n",
    "otherMiscDocCount = 0 # Counting objects that are not letters.\n",
    "authorID = \"\" # Reserved for VIAF etc.\n",
    "# ---------------------------------------------------------------\n",
    "iii = 0\n",
    "for path in glob.glob(inputfolder+\"/*.xml\"):\n",
    "    inputfilepath = path\n",
    "    with open(inputfilepath, \"r\", encoding=\"utf-8\") as file: # Open a file\n",
    "        tei = file.readlines() # Les innholdet som linjer\n",
    "        tei = \"\".join(tei) # Linjene blir kombinert i en variabel\n",
    "    soup = BeautifulSoup(tei, from_encoding=\"UTF-8\") # It is now soup\n",
    "    # Don't worry about the error screaming about Unicode markup being provided twice\n",
    "    print(\"Souped\",inputfilepath)\n",
    "    # Before handling the data: remove all comments\n",
    "    # Making a list of <!--comments--> to be destroyed...\n",
    "    commentDocs = 0 # Used only in terminating comments\n",
    "    comments = 0 # Used only in terminating comments\n",
    "    for comment in soup.findAll(string=lambda text: isinstance(text, Comment)):\n",
    "        if \"xml:id=\\\"\" in comment:\n",
    "            commentDocs+=1\n",
    "        comment.extract()\n",
    "        comments+=1\n",
    "    if comments > 0:\n",
    "        print(\"Destroyed\",comments,\"<!--comments-->, of which\",commentDocs,\"contained an @XML:ID.\")\n",
    "    # ... and checking it twice.\n",
    "    comments = soup.findAll(string=lambda text: isinstance(text, Comment))\n",
    "    if comments:\n",
    "        print(\"There are still\",len(comments),\"comments present.\")\n",
    "    else:\n",
    "        print(\"All comments destroyed.\")\n",
    "    # Limit workspace to individual div (document) here.\n",
    "    profileDescElement = CMIF.find('profiledesc') # Target correspondence wrapper\n",
    "    # For each Div element with an XML:ID (should be each document)\n",
    "    for document in soup.findAll(\"div\", {\"xml:id\":True}):\n",
    "        #print (\"\\r\",\"Progress:\",round(i/len(listXMLfiles)*100),\"%\", end='')\n",
    "        # Get the document ID from the <div> element.\n",
    "        \n",
    "        authorID,authorName,recipient,recipientID = False,False,False,False # debug\n",
    "        \n",
    "        # Look for the document type assignment.\n",
    "        documentType = document.find(\"list\", {\"type\" : \"objectType\"}).findChild(True, recursive=True)#.attrs['n']\n",
    "        if \"brev\" in documentType or \"letter\" in documentType: # Checks if the words \"letter\" or \"brev\" appear in the type\n",
    "            # This code applies to letters as directed by the data type.\n",
    "            documentID = list(document.attrs.values())[0]\n",
    "            #print(documentType)\n",
    "            #print(\"DEBUG Checking\",documentID)\n",
    "            # Check if the document has more than 0 recipients. If there are no recipients, there is no correspAction required.\n",
    "            \n",
    "\n",
    "            # Check if the document has an author.\n",
    "            if \"correspondence\" in path:\n",
    "                authorNameList = document.find(\"item\", {\"n\":\"sender\"}).findChildren(True, recursive=True)\n",
    "                ji=0\n",
    "                for name in authorNameList:\n",
    "                    authorName = authorNameList[ji]\n",
    "                    #authorName = document.find(\"item\", {\"n\":\"sender\"})\n",
    "                    try:\n",
    "                        targetRef = authorName['target']\n",
    "                    except:\n",
    "                        targetRef = \"NONE\"\n",
    "                        if documentID not in documentsLackingTargetReference:\n",
    "                            documentsLackingTargetReference.append(documentID)\n",
    "                    ji+=1\n",
    "                recipient = \"Edvard Munch\"\n",
    "                \n",
    "            else:\n",
    "                authorName = document.find(\"item\", {\"n\":\"author\"})\n",
    "                recipient = document.find(\"item\", {\"n\":\"recipient\"})\n",
    "            if authorName:\n",
    "                #print(authorName)\n",
    "                try:\n",
    "                    authorName = authorName.contents[0]\n",
    "                except:\n",
    "                    authorName = \"No author\"\n",
    "                    print(\"WARNING:\",documentID,\"suffered code 201881X - really bad!\")\n",
    "                    errors_found.append(\"INFO 201881 in \"+str(documentID))\n",
    "                    documentsWithNoAuthor.append(documentID)\n",
    "            else:\n",
    "                authorName = \"No author\"\n",
    "                print(\"WARNING:\",documentID,\"suffered code 201881 no author found!\")\n",
    "                errors_found.append(\"INFO 201881 in \"+str(documentID))\n",
    "                documentsWithNoAuthor.append(documentID)\n",
    "            if authorName == \"Edvard Munch\":\n",
    "                authorID = \"https://viaf.org/viaf/61624802/\"\n",
    "            else:\n",
    "                authorID = targetRef\n",
    "\n",
    "            # Attempt to divine the date or date range of the document. Assumes that each document only has 1 date (or 1 range).\n",
    "            isDocumentUndated = document.find(\"item\", {\"n\":\"undated\"})\n",
    "            if isDocumentUndated:\n",
    "                date = \"s.d.\"\n",
    "                datetype = \"none\"\n",
    "            else:\n",
    "                isDocumentFromTo = document.find(\"date\", {\"from\":True}) # Does the date element have a from assignment? \n",
    "                # Using \"from\" because PN1350 does not have a fromTo attr despite using fromTo. Uses \"from\", though. Works fine.\n",
    "                if isDocumentFromTo: # If it does, and thus has a range (JK, No-MM_T1296 has FROM attr but not a TO attr.)\n",
    "                    doesDocumentHaveToDate = document.find(\"date\", {\"to\":True})\n",
    "                    if doesDocumentHaveToDate:\n",
    "                        fromDate = isDocumentFromTo['from'] # Extract 'from' date. \n",
    "                        #date = \" \".join(date)\n",
    "                        toDate = isDocumentFromTo['to'] # Extract 'to' date.\n",
    "                        datetype = \"range\"\n",
    "                    else:\n",
    "                        date = isDocumentFromTo['from']\n",
    "                        fromDate = isDocumentFromTo['from']\n",
    "                        datetype = \"fromRange\"\n",
    "                        if documentID not in documentsWithBadDates:\n",
    "                            documentsWithBadDates.append(documentID)\n",
    "\n",
    "                else: # If it doesn't:\n",
    "                    yearSent = document.find(\"date\", {\"type\":\"year\",\"when\":True}) # Check for year element\n",
    "                    monthSent = document.find(\"date\", {\"type\":\"month\",\"when\":True}) # Check for month element\n",
    "                    daySent = document.find(\"date\", {\"type\":\"day\",\"when\":True}) # Check for day element\n",
    "                    if yearSent:\n",
    "                        datetype = \"exact\"\n",
    "                        date = yearSent.attrs[\"when\"]\n",
    "                        if monthSent: # Only look for a month if there's a year. That 1 letter with just month/day, tho...\n",
    "                            M = re.sub('[-]', '', monthSent.attrs[\"when\"]) # Strip the random '-' characters in here.\n",
    "                            date+=\"-\"+str(M) # Join month to year by YYYY-MM.\n",
    "                            if daySent: # Only applies if there is a month AND a day. No point having a day if you don't have a month.\n",
    "                                M = re.sub('[-]', '', daySent.attrs[\"when\"]) # Strip the random '-' characters in here, too.\n",
    "                                date+=\"-\"+str(M) # Join month to year-month by YYYY-MM-DD.\n",
    "                    else: # If it doesn't have a year, make one last check\n",
    "                        doesDocumentHaveToDate = document.find(\"date\", {\"to\":True}) # if the date just has a to date...\n",
    "                        if documentID not in documentsWithBadDates:\n",
    "                                documentsWithBadDates.append(documentID)\n",
    "                        if doesDocumentHaveToDate:\n",
    "                            datetype = \"toRange\"\n",
    "                        else:\n",
    "                            datetype = \"none\"\n",
    "                            date = \"s.d.\"\n",
    "                            print(\"WARNING:\",documentID,\"suffered code 301881 - no year found in a specific-year element. Expected in MM_N1071 and MM_N3734.\")\n",
    "                            errors_found.append(\"INFO 301881 in \"+str(documentID))\n",
    "\n",
    "            # Construct CMIF author (\"sent\") element\n",
    "            correspDescElement = soup.new_tag(\"correspDesc\", attrs={\"key\":str(documentID), \"ref\":\"https://www.emunch.no/HYBRID\"+str(documentID)+\".xhtml\", \"source\":cmifUid})\n",
    "            profileDescElement.append(correspDescElement)\n",
    "            if \"correspondence\" in path:\n",
    "                for name in authorNameList:\n",
    "                    targetElementCorrespDesc = CMIF.find(\"correspDesc\", attrs={\"key\":str(documentID)})\n",
    "                    correspActionElement = soup.new_tag(\"correspAction\", attrs={'type':'sent'})\n",
    "                    targetElementCorrespDesc.append(correspActionElement)\n",
    "                    correspActionTarget = targetElementCorrespDesc.findChild(\"correspAction\",attrs={\"type\": \"sent\"}, recursive=False)\n",
    "                    if authorID != \"NONE\":\n",
    "                        persNameElement = soup.new_tag(\"persName\", attrs={\"ref\":authorID})\n",
    "                    else:\n",
    "                        persNameElement = soup.new_tag(\"persName\")\n",
    "                    persNameElement.string = str(authorName)\n",
    "\n",
    "                    correspActionTarget.append(persNameElement)\n",
    "            else:\n",
    "                targetElementCorrespDesc = CMIF.find(\"correspDesc\", attrs={\"key\":str(documentID)})\n",
    "                correspActionElement = soup.new_tag(\"correspAction\", attrs={'type':'sent'})\n",
    "                targetElementCorrespDesc.append(correspActionElement)\n",
    "                correspActionTarget = targetElementCorrespDesc.findChild(\"correspAction\",attrs={\"type\": \"sent\"}, recursive=False)\n",
    "                if authorID != \"NONE\":\n",
    "                    persNameElement = soup.new_tag(\"persName\", attrs={\"ref\":authorID})\n",
    "                else:\n",
    "                    persNameElement = soup.new_tag(\"persName\")\n",
    "                persNameElement.string = str(authorName)\n",
    "\n",
    "                correspActionTarget.append(persNameElement)\n",
    "                \n",
    "            if documentID in placenamedict:\n",
    "                senderLoc = placenamedict[documentID].get('sender')\n",
    "                if senderLoc:\n",
    "                    senderLocEle = soup.new_tag(\"placeName\", attrs={\"ref\":\"(not implemented)\"}) # Create place element\n",
    "                    senderLocEle.string = str(senderLoc) # Give it a string value (placename)\n",
    "                    correspActionTarget.append(senderLocEle) # Append the new element to the correspAction element\n",
    "                    addedPlaceList.append(documentID)\n",
    "                senderDate = placenamedict[documentID].get('date')\n",
    "                if senderDate:\n",
    "                    # Overwrite existing data, if any\n",
    "                    datetype = \"exact\"\n",
    "                    date = senderDate\n",
    "                    changedDatesList.append(documentID)\n",
    "                else:\n",
    "                    senderFromDate = placenamedict[documentID].get('fromDate')\n",
    "                    senderToDate = placenamedict[documentID].get('toDate')\n",
    "                    if senderFromDate and senderToDate:\n",
    "                        datetype = \"range\"\n",
    "                        fromDate = senderFromDate\n",
    "                        toDate = senderToDate\n",
    "                        changedDatesList.append(documentID)\n",
    "                        #print(senderFromDate,senderToDate) # Modify the date (range) here\n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "            if datetype == \"exact\":\n",
    "                dateSentElement = soup.new_tag(\"date\", attrs={\"when\":date})\n",
    "                #print(datetype,date)\n",
    "            elif datetype == \"range\":\n",
    "                dateSentElement = soup.new_tag(\"date\", attrs={\"from\":fromDate,\"to\":toDate})\n",
    "                #print(datetype,fromDate,toDate)\n",
    "            elif datetype == \"fromRange\":\n",
    "                dateSentElement = soup.new_tag(\"date\", attrs={\"from\":fromDate})\n",
    "            elif datetype == \"toRange\":\n",
    "                dateSentElement = soup.new_tag(\"date\", attrs={\"to\":fromDate})\n",
    "                #print(datetype,fromDate)\n",
    "            elif datetype == \"none\":\n",
    "                #print(\"> NO DATE!\",documentID)\n",
    "                pass\n",
    "            else:\n",
    "                print(\"ERROR 2839 - Unrecognized datetype!\")\n",
    "                errors_found.append(\"2839\")\n",
    "            if datetype == \"none\":\n",
    "                pass\n",
    "            else:\n",
    "                # Append date element to correspAction @sent\n",
    "                correspActionTarget.append(dateSentElement)\n",
    "\n",
    "\n",
    "\n",
    "            if recipient: # If there are more than 0 recipients:\n",
    "                letterCount += 1\n",
    "                i=0\n",
    "                if recipient == \"Edvard Munch\":\n",
    "                    recipientID = \"https://viaf.org/viaf/61624802/\"\n",
    "                    recipientType = \"persName\"\n",
    "                    recipientName = recipient\n",
    "                    noOfRecipients += 1\n",
    "                    noOfLettersToMunch += 1\n",
    "                    if recipientName not in addresseesUnique:\n",
    "                        addresseesUnique.append(recipientName)\n",
    "                    correspActionElement = soup.new_tag(\"correspAction\", attrs={'type':'received'})\n",
    "                    targetElementCorrespDesc.append(correspActionElement)\n",
    "                    correspActionTarget = targetElementCorrespDesc.findChildren(\"correspAction\",attrs={\"type\": \"received\"}, recursive=False)\n",
    "\n",
    "                    persNameElement = soup.new_tag(\"persName\", attrs={\"ref\":recipientID})\n",
    "\n",
    "                    persNameElement.string = str(recipientName)\n",
    "                    correspActionTarget[i].append(persNameElement)\n",
    "                    \n",
    "                else:\n",
    "                    recipientList = recipient.findChildren(True) # Get ALL children of the recipient item element. Might be 2+!\n",
    "                    for each in recipientList: # For every recipient:\n",
    "                        recipientName = str(each.contents[0]) # Assign a name\n",
    "                        noOfRecipients += 1\n",
    "                        if recipientName not in addresseesUnique:\n",
    "                            addresseesUnique.append(recipientName)\n",
    "                        recipientID = recipientList[i].attrs[\"target\"] # Assign an ID\n",
    "\n",
    "                        if \"institution\" in recipientID:\n",
    "                            recipientType = \"orgName\"\n",
    "                        elif \"person\" in recipientID:\n",
    "                            recipientType = \"persName\"\n",
    "                        else:\n",
    "                            print(\"WARNING:\",documentID,\"suffered error 20191. Defaulted to person.\")\n",
    "                            recipientType = \"persName\"\n",
    "                            errors_found.append(\"WARNING 20191 in \"+str(documentID))\n",
    "\n",
    "                        correspActionElement = soup.new_tag(\"correspAction\", attrs={'type':'received'})\n",
    "                        targetElementCorrespDesc.append(correspActionElement)\n",
    "                        correspActionTarget = targetElementCorrespDesc.findChildren(\"correspAction\",attrs={\"type\": \"received\"}, recursive=False)\n",
    "\n",
    "                        if recipientType == \"persName\":\n",
    "                            persNameElement = soup.new_tag(\"persName\", attrs={\"ref\":recipientID})\n",
    "                        elif recipientType == \"orgName\":\n",
    "                            persNameElement = soup.new_tag(\"orgName\", attrs={\"ref\":recipientID})\n",
    "\n",
    "                        persNameElement.string = str(recipientName)\n",
    "                        correspActionTarget[i].append(persNameElement)\n",
    "                        i+=1\n",
    "            else: # If document does not have a recipient, what do we do?\n",
    "                miscCount+=1\n",
    "                if documentID not in documentsWithNoRecipient:\n",
    "                    documentsWithNoRecipient.append(documentID)\n",
    "        else:\n",
    "            otherMiscDocCount += 1\n",
    "        #iii+=1\n",
    "        #if iii > 30:\n",
    "         #   raise KeyboardInterrupt\n",
    "            #print(\"Skipped item\",documentID,\"as it is not a letter.\")\n",
    "    #print(\"</profileDesc>\")\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processed\",otherMiscDocCount+letterCount,\"documents.\",str(letterCount)+\"(\"+str(round(letterCount/(otherMiscDocCount+letterCount)*100))+\"%) were letters addressed to \"+str(noOfRecipients)+\" recipients, of which \"+str(len(addresseesUnique))+\" were unique (meaning each person received avg. \"+str(round(letterCount/len(addresseesUnique)))+\" letters), and\",miscCount,\"letters without recipients (if this > 0, there's a problem) in\",round(end - start,1),\"seconds.\")\n",
    "print(\"The register file had 5443 documents of which 2711 were letters. Munch received\",noOfLettersToMunch,\"letters according to my script.\")\n",
    "if len(errors_found) > 0:\n",
    "    i = 0\n",
    "    print(\"\\n\"+str(len(errors_found)),\"data warnings and errors, listed as INFO, WARNING, and ERROR in order of severity:\")\n",
    "    for error in errors_found:\n",
    "        i+=1\n",
    "        if \"201881\" in error:\n",
    "            print(i,error,\"\\n\\tDocument has no author. Registered as \\\"No author\\\".\")\n",
    "        elif \"301881\" in error:\n",
    "            print(i,error,\"\\n\\tDocument has a specific date type, but does not specify or suggest a year (MM-DD/MM). Document has been given \\\"undated\\\" status.\")\n",
    "        elif \"301882\" in error:\n",
    "            print(i,error,\"\\n\\tCatastrophic failure in date format or harvesting. The script was not designed for this.\")\n",
    "        elif \"30190\" in error:\n",
    "            print(i,error,\"\\n\\tCatastrophic failure in recipient list processing. I don't think the script will run to this point with such an error.\")\n",
    "        elif \"20191\" in error:\n",
    "            print(i,error,\"\\n\\tThe recipient is not a person or an organization. Suggests error in reference XMLURI. Defaulted to person.\")\n",
    "        else:\n",
    "            print(\"There is an error that is not indexed. :(\")\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    print(\"No warnings or errors found.\")\n",
    "print(\"Saving to disk.\")\n",
    "start = time.time()\n",
    "with open(outputfolder+\"\\CMIF_Unified.xml\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(CMIF.prettify())\n",
    "end = time.time()\n",
    "print(\"Prettified CMIF file created in\",round(end - start,1),\"seconds.\")\n",
    "print(\"Process complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(CMIF.prettify())\n",
    "print(\"Bad/irregular dates:\",documentsWithBadDates,\"\\nBad/no author:\",documentsWithNoAuthor,\"\\nBad/no recipient:\",documentsWithNoRecipient,\"\\nBad/no target reference:\",documentsLackingTargetReference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(glob.glob(inputfolder+\"/*.xml\")[0], \"r\", encoding=\"utf-8\") as file: # Open a file\n",
    "    tei = file.readlines() # Les innholdet som linjer\n",
    "    tei = \"\".join(tei) # Linjene blir kombinert i en variabel\n",
    "soupA = BeautifulSoup(tei, from_encoding=\"UTF-8\") # It is now soup\n",
    "\n",
    "with open(glob.glob(inputfolder+\"/*.xml\")[1], \"r\", encoding=\"utf-8\") as file: # Open a file\n",
    "    tei = file.readlines() # Les innholdet som linjer\n",
    "    tei = \"\".join(tei) # Linjene blir kombinert i en variabel\n",
    "soupB = BeautifulSoup(tei, from_encoding=\"UTF-8\") # It is now soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=soupA.find(\"div\", {\"xml:id\" : \"No-MM_K5796\"})\n",
    "#doc.find(\"item\", {\"n\":\"sender\"}).findChildren(True, recursive=True)\n",
    "authorNameList = doc.find(\"item\", {\"n\":\"sender\"}).findChildren(True, recursive=True)\n",
    "ji=0\n",
    "for name in authorNameList:\n",
    "    authorName = authorNameList[ji]\n",
    "    #authorName = document.find(\"item\", {\"n\":\"sender\"})\n",
    "    try:\n",
    "        targetRef = authorName['target']\n",
    "    except:\n",
    "        targetRef = \"NONE\"\n",
    "    print(ji,authorName,targetRef)\n",
    "    ji+=1\n",
    "\n",
    "# MM_K3421 viser en instans av at det er kodet inn item n@sender og ref, men mangler innhold i begge. Dårlig. Har jo ikke recipient helle\n",
    "\n",
    "# MM_N3734 er notater på MM_K4982. MM_K4982 opptrer ikke som objekt i XML-filen jeg har fått. Hmm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsAttrs = [] # New list\n",
    "for x in soup.findAll(): # For every tag in the soup\n",
    "    tag = str(x.name) # Assign name of tag to var tag\n",
    "    for attribute in x.attrs: # For every attribute belonging to the tag\n",
    "        tag = tag+\" @\"+attribute # Append attribute to tag with \" @\" as separator - results in combination\n",
    "    if tag not in tagsAttrs: # If this particular combination of tag/attribute(s) has not been seen previously\n",
    "        tagsAttrs.append(tag) # Register it in our list\n",
    "# Dict with known tag/attribute pairings and understood meanings\n",
    "dict = {\n",
    "    \"tei\":\"The TEI element - is where our file actually begins.\",\n",
    "    \"teiheader\":\"The TEI header contains metadata (titleStmt, publicationStmt, sourceDesc...).\",\n",
    "    \"p\":\"P is a paragraph. This is used in the TEIheader to contain the actual strings for publication & source desc. And a single, random </p> element later.\",\n",
    "    \"body\":\"Body is used as a sub-element of <text> to contain all the metadata for all letters. I am personally offended by this practice. BS4 adds one, too.\",\n",
    "    \"text\":\"Text appears to be a wrapper for the body tag, which contains all the texts' metadata.\",\n",
    "    \"div\":\"Div, with @xml:id, is used to contain the metadata of a single letter.\",\n",
    "    \"date\":\"Date is a date element. It seems to have the @when attribute very often, as well as enclosed text. Often has @type(year/fromTo, etc.)\",\n",
    "    \"table\":\"Table is the primary data structure in which information about each letter is stored. This is a *table*.\",\n",
    "    \"row\":\"Row is a sub-element of the table element. It defines a new X-axis in a table.\",\n",
    "    \"seg\":\"Seg appears to be some kind of ID attached to each letter. The ID is used as an @xml:id attribute in div, and the element appears in references to other letters.\",\n",
    "    \"cell\":\"Cell is a sub-element of the table element also. A single cell appears to be an entry into a row element.\",\n",
    "    \"ref\":\"Ref appears to contain references to other XML items.\",\n",
    "    \"item\":\"Item is a generic element that has multiple @attributes, such as owner, owner signature, author, paper type... This is evidently a very important tag.\",\n",
    "    \"list\":\"List is a list. Often, the list only has one item. The list is used as description tag, containing other lists, and describes anything between dates to material type.\",\n",
    "    \"html\":\"The HTML tag can be ignored. BS4 adds this.\",\n",
    "    \"filedesc\":\"Filedesc contains title, publication, source statements.\",\n",
    "    \"sourcedesc\":\"Sourcedesc describes the source of the whole document.\",\n",
    "    \"publicationstmt\":\"Publication statement for the whole document.\",\n",
    "    \"title\":\"Title for the whole document.\",\n",
    "    \"titlestmt\":\"Titlestmt is a wrapper for the title tag (whole document).\",\n",
    "    \"div @xml:id\":\"Div has an attribute @xml:id. This describes the unique ID of the item in question.\",\n",
    "    \"list @type\":\"List's @type attribute describes whether the list is wrapped around an object/physical description, a date, or other category.\",\n",
    "    \"item @n\":\"Item's @n attribute describes role, library sorting, language, measures, dated, notes and so on. Very... multipurpose.\",\n",
    "    \"tei @xmlns @xml:id\":\"tei @xmlns @xml:id is functionally identical to TEI tag. Just the one.\",\n",
    "    \"date @type @from @to\":\"date @type @from @to describes the sequence type=fromTo, from, to. A date range.\",\n",
    "    \"ref @target\":\"ref's @target attribute describes a URL to another XML.\",\n",
    "    \"date @type @when\":\"Date with attributes type and when. Single date/year.\",\n",
    "    \"ref @type @target\":\"Seems to contain URL to eMunch's web pages for a 'Read More' function.\",\n",
    "    \"date @type @from\":\"date @type @from is an open-ended date.\",\n",
    "    \"date @type\":\"Caution: date @type is a date with just a type. The date itself might be enclosed...? Potentially misleading. Investigate.\",\n",
    "    \"ref @target @n\":\"ref @target @n - like ref @target, but @n tends to be the name of an institution or so.\",\n",
    "    \"row @n\":\"row @n describes parts of the text. Inventory number, paper type, etc.\",\n",
    "    \"ref @type @target @n\":\"ref @type @target @n - Working off of previous information, I'll infer that ref @type @target @n describes a Read More, with URL, with name.\"\n",
    "}\n",
    "print(\"Listing all unique tags and attribute combinations found with mapped, understood meanings.\\n\")\n",
    "tagsAttrs.sort() # We do a little sorting\n",
    "for x in tagsAttrs: # For every tag/attr combination registered\n",
    "    if x in dict: # If our dict has the combo\n",
    "        if \"@\" in x: # If there's an attribute involved\n",
    "            print(\"ATTR [\"+str(x)+\"]\",dict[x]) # Print with attribute focus\n",
    "        else: # If there is no attribute involved\n",
    "            print(\"TAG [\"+str(x)+\"]\",dict[x]) # Print with tag focus\n",
    "    else: # If our dict does not have the combo\n",
    "        print(\"\\n\"+str(x),\"has no description. What is this?\\n\") # Print error\n",
    "comments = soup.find_all(string=lambda text: isinstance(text, Comment)) # Find all comments in soup\n",
    "if comments: # If there are comments\n",
    "    n = len(comments) # Check how many comments\n",
    "    print(\"\\n> Detected\",n,\"comments (<!-- -->, etc). These should be eradicated before tag extraction.\") # Print message\n",
    "else: # If there are no comments\n",
    "    print(\"\\n> There are no (0) comments to worry about in this document.\") # There are no comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have notes as well as letters. The notes generally do not have a item @recipient tag, while the letters generally do.\n",
    "\n",
    "Every div has an xml:id, and an enclosed ID.\n",
    "\n",
    "Every item then has a list with items in it.\n",
    "\n",
    "#### Debug stuff - Types of attributes\n",
    "There's a whole lot of item *n* tags. What are they? Let's find out. The following extracts list and item tags with unique attribute texts. We have to filter out a loooot of tags that're IDs, dates etc. And look - we got cells, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemNs = []\n",
    "itemXmlIds = []\n",
    "itemDates = []\n",
    "itemTargets = []\n",
    "lists = itemNs,itemXmlIds,itemDates,itemTargets\n",
    "for x in soup.findAll(True):\n",
    "    name = x.name\n",
    "    if \"list\" in name:\n",
    "        children = x.findChildren(True, recursive=True)\n",
    "        i=0\n",
    "        for child in children:\n",
    "            if len(child.attrs) == 0:\n",
    "                print(\"Child of\",name,i,child.name,\"\\n\")\n",
    "            else:\n",
    "                print(\"Child of\",name,i,child.name,child.attrs,\"\\n\")\n",
    "            i+=1\n",
    "    for i in x.attrs:\n",
    "        attribute = i\n",
    "        value = x.attrs[i]\n",
    "        try:\n",
    "            contents = x.contents[0]\n",
    "            fullTag = str(name)+\" @\"+str(attribute)+\" = \"+str(value)+\" \"+str(contents)\n",
    "        except:\n",
    "            fullTag = str(name)+\" @\"+str(attribute)+ \"= \"+str(value)\n",
    "        if \"@xml:id\" in fullTag:\n",
    "            if fullTag not in itemXmlIds:\n",
    "                itemXmlIds.append(fullTag)\n",
    "        elif \"date\" in fullTag:\n",
    "            if fullTag not in itemDates:\n",
    "                itemDates.append(fullTag)\n",
    "        elif \"@target\" in fullTag:\n",
    "            if fullTag not in itemTargets:\n",
    "                itemTargets.append(fullTag)   \n",
    "        else:\n",
    "            if fullTag not in itemNs:\n",
    "                itemNs.append(fullTag)\n",
    "#for x in lists:\n",
    "#    x.sort()\n",
    "#itemNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://correspsearch.net/en/documentation.html\n",
    "\n",
    "/correspAction/@type == correspAction element with attribute type=\"xyz\"\n",
    "\n",
    "/correspAction/persName == correspAction element with persName child element\n",
    "\n",
    "@X == attribute of element\n",
    "\n",
    "*Each letter, postcard - document - that is to be described features its own **correspDesc element**. *There are as many correspDescs as there are items. A particular correspDesc element in CMI format is more restrictive and reduced with regard to its vocabulary than the TEI Guidlines generally allow. This enables interchange between the respective TEI documents.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each in letters:\n",
    "    create correspDesc wrapper\n",
    "    \n",
    "<correspDesc>\n",
    "    <correspAction type=\"sent\">\n",
    "        <persName ref=\"VIAFetc url\">NAME</>\n",
    "        <placeName ref=\"Geonames url\">NAME</>\n",
    "    <correspAction type=\"received\">\n",
    "        <persName ref=\"url\">NAME</>\n",
    "        <placeName ref=\"Geonames url\">NAME</>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping tags\n",
    "*Italics* == Tag is category/folder only, does not contain text in itself\n",
    "\n",
    "#### TEI-Header (metadata)\n",
    "1. *Titlestmt* {Title, Editor(email)}\n",
    "2. *Publicationstmt* {*Publisher* (Ref @target), idno@url, date@when, *Availability*(licence@target)}\n",
    "3. *Sourcedesc* {Bibl@type@xml:id} - type=\"online\" xml:id=\"cmifUid\"\n",
    "\n",
    "The header mostly features direct correlation, or items where the program will directly inject new information.\n",
    "\n",
    "Now, because nothing is easy, the example file is just all TEI header including the letters it wants to describe. There is a body tag with a random \\<p/>, which just serves absolutely no purpose. Why?\n",
    "\n",
    "#### \"profileDesc\" (data)\n",
    "1. correspDesc @key @ref @source {correspAction @type (persname @ref, placename @ref, *date @when*), correspAction @type (persname @ref, placename @ref, *date @when*)}\n",
    "\n",
    "Dates need to be YYYY-MM-DD, dropping DD and/or MM if required. Unknown dates should be skipped as per CMIF documentation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replaced, functional(?) code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit workspace to individual div (document) here.\n",
    "profileDescElement = CMIF.find('profiledesc') # Target correspondence wrapper\n",
    "# For each Div element with an XML:ID (should be each document)\n",
    "for document in soup.findAll(\"div\", {\"xml:id\":True}):\n",
    "    # Get the document ID from the <div> element.\n",
    "    # Look for the document type assignment.\n",
    "    documentType = document.find(\"list\", {\"type\" : \"objectType\"}).findChild(True, recursive=True)#.attrs['n']\n",
    "    if \"brev\" in documentType or \"letter\" in documentType: # Checks if the words \"letter\" or \"brev\" appear in the type\n",
    "        # This code applies to letters as directed by the data type.\n",
    "        documentID = list(document.attrs.values())[0]\n",
    "        #print(documentType)\n",
    "        #print(\"DEBUG Checking\",documentID)\n",
    "        # Check if the document has more than 0 recipients. If there are no recipients, there is no correspAction required.\n",
    "        recipient = document.find(\"item\", {\"n\":\"recipient\"})\n",
    "\n",
    "        # Check if the document has an author.\n",
    "        authorName = document.find(\"item\", {\"n\":\"author\"})\n",
    "        if authorName:\n",
    "            #print(authorName)\n",
    "            authorName = authorName.contents[0]\n",
    "        else:\n",
    "            authorName = \"No author\"\n",
    "            print(\"WARNING:\",documentID,\"suffered code 201881 no author found!\")\n",
    "            errors_found.append(\"INFO 201881 in \"+str(documentID))\n",
    "        if authorName == \"Edvard Munch\":\n",
    "            authorID = \"https://viaf.org/viaf/61624802/\"\n",
    "        else:\n",
    "            authorID = \"Add author ID mechanism.\"\n",
    "\n",
    "        # Attempt to divine the date or date range of the document. Assumes that each document only has 1 date (or 1 range).\n",
    "        isDocumentUndated = document.find(\"item\", {\"n\":\"undated\"})\n",
    "        if isDocumentUndated:\n",
    "            date = \"s.d.\"\n",
    "            datetype = \"none\"\n",
    "        else:\n",
    "            isDocumentFromTo = document.find(\"date\", {\"from\":True}) # Does the date element have a from assignment? \n",
    "            # Using \"from\" because PN1350 does not have a fromTo attr despite using fromTo. Uses \"from\", though. Works fine.\n",
    "            if isDocumentFromTo: # If it does, and thus has a range (JK, No-MM_T1296 has FROM attr but not a TO attr.)\n",
    "                doesDocumentHaveToDate = document.find(\"date\", {\"to\":True})\n",
    "                if doesDocumentHaveToDate:\n",
    "                    fromDate = isDocumentFromTo['from'] # Extract 'from' date. \n",
    "                    #date = \" \".join(date)\n",
    "                    toDate = isDocumentFromTo['to'] # Extract 'to' date.\n",
    "                    datetype = \"range\"\n",
    "                else:\n",
    "                    date = isDocumentFromTo['from']\n",
    "                    datetype = \"fromRange\"\n",
    "                \n",
    "            elif not isDocumentFromTo: # If it doesn't:\n",
    "                yearSent = document.find(\"date\", {\"type\":\"year\",\"when\":True}) # Check for year element\n",
    "                monthSent = document.find(\"date\", {\"type\":\"month\",\"when\":True}) # Check for month element\n",
    "                daySent = document.find(\"date\", {\"type\":\"day\",\"when\":True}) # Check for day element\n",
    "                if yearSent:\n",
    "                    datetype = \"exact\"\n",
    "                    date = yearSent.attrs[\"when\"]\n",
    "                    if monthSent: # Only look for a month if there's a year. That 1 letter with just month/day, tho...\n",
    "                        M = re.sub('[-]', '', monthSent.attrs[\"when\"]) # Strip the random '-' characters in here.\n",
    "                        date+=\"-\"+str(M) # Join month to year by YYYY-MM.\n",
    "                        if daySent: # Only applies if there is a month AND a day. No point having a day if you don't have a month.\n",
    "                            M = re.sub('[-]', '', daySent.attrs[\"when\"]) # Strip the random '-' characters in here, too.\n",
    "                            date+=\"-\"+str(M) # Join month to year-month by YYYY-MM-DD.\n",
    "                else:\n",
    "                    datetype = \"none\"\n",
    "                    date = \"s.d.\"\n",
    "                    print(\"WARNING:\",documentID,\"suffered code 301881 - no year found in a specific-year element. Expected in MM_N1071 and MM_N3734.\")\n",
    "                    errors_found.append(\"INFO 301881 in \"+str(documentID))\n",
    "            else:\n",
    "                datetype = \"Warning 301882\"\n",
    "                print(\"WARNING:\",documentID,\"suffered error 301882 - catastrophic date error\")\n",
    "                errors_found.append(\"CRITICAL ERROR 301882 in \"+str(documentID))\n",
    "        \n",
    "        # Construct CMIF author (\"sent\") element\n",
    "        correspDescElement = soup.new_tag(\"correspDesc\", attrs={\"key\":str(documentID), \"ref\":\"https://www.emunch.no/HYBRID\"+str(documentID)+\".xhtml\", \"source\":cmifUid})\n",
    "        profileDescElement.append(correspDescElement)\n",
    "\n",
    "        targetElementCorrespDesc = CMIF.find(\"correspDesc\", attrs={\"key\":str(documentID)})\n",
    "        correspActionElement = soup.new_tag(\"correspAction\", attrs={'type':'sent'})\n",
    "        targetElementCorrespDesc.append(correspActionElement)\n",
    "        correspActionTarget = targetElementCorrespDesc.findChild(\"correspAction\",attrs={\"type\": \"sent\"}, recursive=False)\n",
    "        persNameElement = soup.new_tag(\"persName\", attrs={\"ref\":authorID})\n",
    "        persNameElement.string = str(authorName)\n",
    "        \n",
    "        correspActionTarget.append(persNameElement)\n",
    "        \n",
    "        if datetype == \"exact\":\n",
    "            dateSentElement = soup.new_tag(\"date\", attrs={\"when\":date})\n",
    "            #print(datetype,date)\n",
    "        elif datetype == \"range\":\n",
    "            dateSentElement = soup.new_tag(\"date\", attrs={\"from\":fromDate,\"to\":toDate})\n",
    "            #print(datetype,fromDate,toDate)\n",
    "        elif datetype == \"fromRange\":\n",
    "            dateSentElement = soup.new_tag(\"date\", attrs={\"from\":fromDate})\n",
    "            #print(datetype,fromDate)\n",
    "        elif datetype == \"none\":\n",
    "            #print(\"> NO DATE!\",documentID)\n",
    "            pass\n",
    "        else:\n",
    "            print(\"ERROR 2839 - Unrecognized datetype!\")\n",
    "            errors_found.append(\"2839\")\n",
    "        if datetype == \"none\":\n",
    "            pass\n",
    "        else:\n",
    "            # Append date element to correspAction @sent\n",
    "            correspActionTarget.append(dateSentElement)\n",
    "\n",
    "\n",
    "        \n",
    "        if recipient: # If there are more than 0 recipients:\n",
    "            letterCount += 1\n",
    "            i=0\n",
    "            recipientList = recipient.findChildren(True) # Get ALL children of the recipient item element. Might be 2+!\n",
    "            for each in recipientList: # For every recipient:\n",
    "                recipientName = str(each.contents[0]) # Assign a name\n",
    "                noOfRecipients += 1\n",
    "                if recipientName not in addresseesUnique:\n",
    "                    addresseesUnique.append(recipientName)\n",
    "                recipientID = recipientList[i].attrs[\"target\"] # Assign an ID\n",
    "\n",
    "                if \"institution\" in recipientID:\n",
    "                    recipientType = \"orgName\"\n",
    "                elif \"person\" in recipientID:\n",
    "                    recipientType = \"persName\"\n",
    "                else:\n",
    "                    print(\"WARNING:\",documentID,\"suffered error 20191. Defaulted to person.\")\n",
    "                    recipientType = \"persName\"\n",
    "                    errors_found.append(\"WARNING 20191 in \"+str(documentID))\n",
    "\n",
    "                correspActionElement = soup.new_tag(\"correspAction\", attrs={'type':'received'})\n",
    "                targetElementCorrespDesc.append(correspActionElement)\n",
    "                correspActionTarget = targetElementCorrespDesc.findChildren(\"correspAction\",attrs={\"type\": \"received\"}, recursive=False)\n",
    "\n",
    "                if recipientType == \"persName\":\n",
    "                    persNameElement = soup.new_tag(\"persName\", attrs={\"ref\":recipientID})\n",
    "                elif recipientType == \"orgName\":\n",
    "                    persNameElement = soup.new_tag(\"orgName\", attrs={\"ref\":recipientID})\n",
    "\n",
    "                persNameElement.string = str(recipientName)\n",
    "                correspActionTarget[i].append(persNameElement)\n",
    "                i+=1\n",
    "        else: # If document does not have a recipient, what do we do?\n",
    "            miscCount+=1\n",
    "    else:\n",
    "        otherMiscDocCount += 1\n",
    "        #print(\"Skipped item\",documentID,\"as it is not a letter.\")\n",
    "#print(\"</profileDesc>\")\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
